The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centered and occupies about the same amount of space in each image. Each image corresponds to a facial expression in one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral). The dataset contains approximately 36K images. 
I used Convolutional Neural Networks to predict the face expression in real time. I used some powerful python libraries for this project libraries like tensorflow, openCV and Flask. If you want to check this out all you have do is run the main file.
